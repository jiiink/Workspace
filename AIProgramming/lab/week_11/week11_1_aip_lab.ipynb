{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQTQkVBu4JAa"
      },
      "source": [
        "# Version History\n",
        "\n",
        "VERSION 0.3:\n",
        "* Removed current_solution initialization from the constructor.\n",
        "* Added num_neighbor to control the number of neighbors generated per iteration.\n",
        "* Added best_score_idx, a lambda function to find the index of the best score from a list of scores. This is used when evaluating multiple neighbors.\n",
        "* The current solution is now initialized at the start of the fit method.\n",
        "* Generates multiple neighbors (num_neighbor) per iteration and evaluates them.\n",
        "* Selects the best neighbor based on the scores and updates the current and best solutions if necessary.\n",
        "* Implements the random restart mechanism. It calls fit method multiple times (num_restarts) and keeps track of the overall best solution.\n",
        "\n",
        "\n",
        "VERSION 0.2:\n",
        "* Introduced the mode parameter to toggle between maximization and minimization.\n",
        "* Added a lambda function, is_better, to abstract the comparison logic based on the mode.\n",
        "* The best_score is now set based on the mode of operation.\n",
        "* The fit method is updated to use the is_better function for comparison.\n",
        "\n",
        "\n",
        "\n",
        "VERSION 0.1:\n",
        "* Basic hill climbing functionality to maximize an objective function.\n",
        "* The fit method only seeks to improve (maximize) the objective function score.\n",
        "* The best_score is initialized to negative infinity to ensure any score is better.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kL7hzb8tP7lO"
      },
      "source": [
        "# Hill Climber Class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1S1KALY3psI"
      },
      "source": [
        "|   | Hill Climbing Algorithm | Neighbor Generation                       | Number of Neighbors    | Termination                                   | Exploration vs. Exploitation |\n",
        "|---|-------------------------|-------------------------------------------|------------------------|-----------------------------------------------|------------------------------|\n",
        "| V | First-choice            | Random neighbor, stops when better found  | 1 until better found   | No improvement for a set number of iterations | Mostly exploitation          |\n",
        "| V | Steepest Ascent         | All possible neighbors, best selected     | All possible neighbors | No better neighbor found                      | Pure exploitation            |\n",
        "|   | Gradient Descent        | Next point based on gradient              | 1                      | No improvement in next step                   | Pure exploitation            |\n",
        "|   | Stochastic              | Multiple neighbors, chosen stochastically | Multiple               | No improvement for a set number of iterations | Mostly exploitation          |\n",
        "|   | Simulated Annealing     | Random neighbor                           | 1                      | Temperature reaches zero or eval limit        | Balanced                     |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Uj49mEmRTlL"
      },
      "source": [
        "<img src=\"https://www.researchgate.net/profile/John-Hogden/publication/291419889/figure/fig2/AS:320895026515974@1453518744135/Schematic-showing-the-trade-off-between-exploration-and-exploitation-A-hypothetical.png\" width=400>\n",
        "\n",
        "> Schematic showing the trade-off between **exploration** and **exploitation**.: A hypothetical fitness landscape (shown as continuous red line) from the regression model in an abstract high-dimensional feature space with two local maxima. One of the maxima has a data point with a relatively large value for mean, but small uncertainty (error bar). This is due to its close proximity to the best material that is known so far in the training set (blue circle), where the regression algorithm has trained well. The other local maximum, in contrast, has a data point with small mean value (red circle), but relatively large uncertainty.\n",
        "\n",
        "Prasanna V. Balachandran et. al., Adaptive Strategies for Materials Design using Uncertainties (2016)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ptW40mosp1kr"
      },
      "outputs": [],
      "source": [
        "class HillClimber:\n",
        "  def __init__(self, generate_neighbor,\n",
        "                objective_function,\n",
        "                initial_solution_generator,\n",
        "                step_size=0.01,\n",
        "                num_neighbors=1,\n",
        "                learning_rate=0.01,\n",
        "                max_iter=1000,\n",
        "                mode='max',\n",
        "                num_restarts=10,\n",
        "                ):\n",
        "    self.generate_neighbor = generate_neighbor\n",
        "    self.objective_function = objective_function\n",
        "    self.initial_solution_generator = initial_solution_generator\n",
        "    self.step_size = step_size\n",
        "    self.num_neighbors = num_neighbors\n",
        "    self.max_iter = max_iter\n",
        "    self.best_solution = None\n",
        "    self.best_score = None\n",
        "    self._setup_mode(mode)\n",
        "    self.num_restarts = num_restarts\n",
        "\n",
        "  def _setup_mode(self, mode):\n",
        "    if mode == 'max':\n",
        "      self.best_score = float('-inf')\n",
        "      self.is_better = lambda new, best: new > best\n",
        "      self.best_score_idx = lambda scores: np.argmax(scores)\n",
        "    else:\n",
        "      self.best_score = float('inf')\n",
        "      self.is_better = lambda new, best: new < best\n",
        "      self.best_score_idx = lambda scores: np.argmin(scores)\n",
        "\n",
        "  def fit(self):\n",
        "    self.current_solution = self.initial_solution_generator()\n",
        "    # print(\"current_solution\", self.current_solution)\n",
        "    for _ in range(self.max_iter):\n",
        "      neighbors = self.generate_neighbor(solution=self.current_solution, step_size=self.step_size, num_neighbors=self.num_neighbors)\n",
        "      # print(\"neighbors\", neighbors)\n",
        "      neighbors_scores = [self.objective_function(*neighbor) for neighbor in neighbors]\n",
        "      best_neighbor_index = self.best_score_idx(neighbors_scores)\n",
        "      best_neighbor = neighbors[best_neighbor_index]\n",
        "\n",
        "      if self.is_better(neighbors_scores[best_neighbor_index], self.best_score):\n",
        "        self.best_solution = best_neighbor\n",
        "        self.best_score = neighbors_scores[best_neighbor_index]\n",
        "        self.current_solution = best_neighbor\n",
        "\n",
        "    return self.best_solution\n",
        "\n",
        "  def predict(self):\n",
        "    return self.best_solution\n",
        "\n",
        "  def score(self):\n",
        "    return self.best_score\n",
        "\n",
        "  def random_restart(self):\n",
        "    for _ in range(self.num_restarts):\n",
        "      self.fit()\n",
        "      new_solution = self.predict()\n",
        "      new_score = self.score()\n",
        "\n",
        "      if self.is_better(new_score, self.best_score):\n",
        "        self.best_solution = new_solution\n",
        "        self.best_score = new_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOH6d9g7QkOn"
      },
      "source": [
        "#3. GradientDescentHillClimber\n",
        "\n",
        "GradientDescentHillClimber class using the convex_function as the objective function. We will test these classes to see if they can minimize this function, starting from a random initial solution in a 5-dimensional space.\n",
        "\n",
        "```\n",
        "def convex_function(x):\n",
        "    return (x[0] - 2) ** 2 + 5 * (x[1] - 5) ** 2 + 8 * (x[2] + 8) ** 2 + 3 * (x[3] + 1) ** 2 + 6 * (x[4] - 7) ** 2\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IneMa_3zVuLL"
      },
      "source": [
        "## Numerical_differentiation\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/1/18/Derivative.svg/460px-Derivative.svg.png\" width=400>\n",
        "\n",
        "https://en.wikipedia.org/wiki/Numerical_differentiation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "grGkh3FrXpzO",
        "outputId": "37a7dd9a-d506-4a84-81ed-36ade2c5aed0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Y17-mRYkkG_4"
      },
      "outputs": [],
      "source": [
        "class GradientDescentHillClimber(HillClimber):\n",
        "    def __init__(self, gradient_function, objective_function, initial_solution_generator, step_size=0.1, num_neighbor=1, learning_rate=0.01, max_iter = 100000, mode = 'min', num_restarts = 10):\n",
        "        super().__init__(gradient_function, objective_function, initial_solution_generator, step_size, num_neighbor, learning_rate, max_iter, mode, num_restarts)\n",
        "    def fit(self):\n",
        "        self.current_solution = initial_solution_generator()\n",
        "        \n",
        "        for _ in range(self.max_iter):\n",
        "            new_solution = self.generate_neighbor(solution=self.current_solution)\n",
        "            new_score = self.objective_function(new_solution)\n",
        "            \n",
        "            if new_score < self.best_score:\n",
        "                self.best_score = new_score\n",
        "                self.best_solution = new_solution\n",
        "                self.current_solution = new_solution\n",
        "        \n",
        "        return self.best_solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrkZJnBy_7OV",
        "outputId": "a502c53c-9d54-4ac8-fdb4-4c72a9796a78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradient Descent Hill Climber Best Solution: [1.9999949999999946, 4.999995000000004, -8.000005, -1.0000049999999983, 6.999994999999998]\n",
            "Gradient Descent Hill Climber Best Score: 0.00000\n"
          ]
        }
      ],
      "source": [
        "from functools import partial\n",
        "import numpy as np\n",
        "\n",
        "def convex_function(x):\n",
        "  return (x[0] - 2) ** 2 + 5 * (x[1] - 5) ** 2 + 8 * (x[2] + 8) ** 2 + 3 * (x[3] + 1) ** 2 + 6 * (x[4] - 7) ** 2\n",
        "\n",
        "def initial_solution_generator(n=5):\n",
        "  return [np.random.uniform(-30, 30) for _ in range(n)]\n",
        "\n",
        "# Numerical gradient approximation function\n",
        "def numerical_gradient(f, solution, step_size=0.1, num_neighbors=1, learning_rate=0.01, h=1e-5):\n",
        "  new_solution = []\n",
        "  np_solution = np.array(solution)\n",
        "  fx = f(np_solution)\n",
        "  \n",
        "  for i in range(len(solution)):\n",
        "    np_solution_h = np_solution.copy()\n",
        "    np_solution_h[i] += h\n",
        "    fx_h = f(np_solution_h)\n",
        "    gradient = (fx_h - fx) / h\n",
        "    new_solution.append(np_solution[i] - learning_rate*gradient)\n",
        "    \n",
        "  return new_solution\n",
        "  pass\n",
        "\n",
        "initial_solution_generator = partial(initial_solution_generator, 5)\n",
        "objective_function = partial(numerical_gradient, f=convex_function)\n",
        "\n",
        "# Test the GradientDescentHillClimber class\n",
        "hill_climber = GradientDescentHillClimber(\n",
        "    gradient_function=objective_function,\n",
        "    objective_function=convex_function,\n",
        "    initial_solution_generator=initial_solution_generator,\n",
        ")\n",
        "\n",
        "hill_climber.fit()\n",
        "\n",
        "print(f\"Gradient Descent Hill Climber Best Solution: {hill_climber.predict()}\")\n",
        "print(f\"Gradient Descent Hill Climber Best Score: {hill_climber.score():.5f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0GuNcIsGMkJ",
        "outputId": "341b8a11-2311-488a-be2b-ae9fc24e067e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on function numerical_gradient in module __main__:\n",
            "\n",
            "numerical_gradient(f, solution, step_size=0.1, num_neighbors=1, learning_rate=0.01, h=1e-05)\n",
            "    # Numerical gradient approximation function\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(numerical_gradient)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsPk_819Nm9N"
      },
      "source": [
        "# 1. FirstChoiceHillClimber\n",
        "\n",
        "Given the base class HillClimber, implement a FirstChoiceHillClimber class that extends the functionality of hill climbing by selecting the first neighboring solution that is better than the current solution. Override the fit method to perform the hill climbing process, predict to return the best solution found, and score to return the objective value of the best solution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPsgKsUWQGI8"
      },
      "outputs": [],
      "source": [
        "class FirstChoiceHillClimber(HillClimber):\n",
        "  def fit(self):\n",
        "    self.current_solution = self.initial_solution_generator()\n",
        "    # print(\"current_solution\", self.current_solution)\n",
        "    for count in range(self.max_iter):\n",
        "      neighbors = self.generate_neighbor(solution=self.current_solution, step_size=self.step_size, num_neighbors=self.num_neighbors)\n",
        "      # print(\"neighbors\", neighbors)\n",
        "      neighbors_scores = [self.objective_function(*neighbor) for neighbor in neighbors]\n",
        "      best_neighbor_index = self.best_score_idx(neighbors_scores)\n",
        "      best_neighbor = neighbors[best_neighbor_index]\n",
        "\n",
        "      if self.is_better(neighbors_scores[best_neighbor_index], self.best_score):\n",
        "        self.best_solution = best_neighbor\n",
        "        self.best_score = neighbors_scores[best_neighbor_index]\n",
        "        self.current_solution = best_neighbor\n",
        "\n",
        "    return self.best_solution\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "initial [22.522668068721536, 24.70589964983489, 20.37151365650434, 5.21549585917203, -21.415183318402917]\n",
            "Gradient Descent Hill Climber Best Solution: [ 2.00545753  4.99510753 -7.9974673  -0.99091947  6.99658984]\n",
            "Gradient Descent Hill Climber Best Score: 0.00052\n"
          ]
        }
      ],
      "source": [
        "from functools import partial\n",
        "import numpy as np\n",
        "\n",
        "def convex_function(*x):\n",
        "  # x = [2, 5, -8, -1, 7]\n",
        "  return (x[0] - 2) ** 2 + 5 * (x[1] - 5) ** 2 + 8 * (x[2] + 8) ** 2 + 3 * (x[3] + 1) ** 2 + 6 * (x[4] - 7) ** 2\n",
        "\n",
        "def initial_solution_generator(n=5):\n",
        "  initial_solution = [np.random.uniform(-30, 30) for _ in range(n)]\n",
        "  print(\"initial\", initial_solution)\n",
        "  return initial_solution\n",
        "\n",
        "def generate_neighbor(solution, step_size=0.1, num_neighbors=1):\n",
        "  neighbor = []\n",
        "  neighbor.append(solution + np.random.uniform(-step_size, step_size, len(solution)))\n",
        "  return neighbor\n",
        "  pass\n",
        "\n",
        "initial_solution_generator = partial(initial_solution_generator, 5)\n",
        "objective_function = partial(numerical_gradient, f=convex_function)\n",
        "\n",
        "# Test the GradientDescentHillClimber class\n",
        "hill_climber = FirstChoiceHillClimber(\n",
        "    generate_neighbor,\n",
        "    convex_function,\n",
        "    initial_solution_generator,\n",
        "    mode='min',\n",
        "    max_iter=100000\n",
        ")\n",
        "\n",
        "hill_climber.fit()\n",
        "\n",
        "print(f\"Gradient Descent Hill Climber Best Solution: {hill_climber.predict()}\")\n",
        "print(f\"Gradient Descent Hill Climber Best Score: {hill_climber.score():.5f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3ep3TEHMv_l"
      },
      "source": [
        "#2. SteepestAscentHillClimber\n",
        "\n",
        "\n",
        "Using the provided HillClimber class, create a SteepestAscentHillClimber class that finds the best neighbor out of all possible neighbor solutions generated in one iteration and moves to it if it is better than the current solution. Implement fit, predict, and score methods according to the class' operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPvzCtWi6YoK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DudJvXNo6agn"
      },
      "source": [
        "# 4. RandomRestartHillClimber ??\n",
        "\n",
        "Random Restart is a strategy used to overcome the limitations of local search algorithms, which might get stuck in local optima. The idea is to run a local search algorithm repeatedly from different random starting points.\n",
        "\n",
        "> Compared to these algorithms (FirstChoice, Steepest, GradientDescent), the random restart mechanism is actually a different approach.\n",
        "\n",
        "```\n",
        "for _ in range(num_restarts):\n",
        "  algorithm.fit()\n",
        "  new_solution = algorithm.predict()\n",
        "  new_score = algorithm.score()\n",
        "  if (is_better(best_score, new_score):\n",
        "    best_solution = new_solution\n",
        "    best_score = new_score\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRqOey9I6ewJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxXTtUHHQ8n-"
      },
      "source": [
        "# Evaluation Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgiWOgNv2R6J"
      },
      "source": [
        "\n",
        "\n",
        "| Ackley | Griewank | Convex |\n",
        "|------|----------|-----|\n",
        "| <img src=\"https://drive.google.com/uc?id=1M1slit0Toi9fSt5A_XFPLHdC73vue9-_\" width=\"400\"/>   | <img src=\"https://drive.google.com/uc?id=1dz2iCffrUXVa7bB4ohxjvDXPp3ud0vTO\" width=\"400\"/>      |   <img src=\"https://drive.google.com/uc?id=1FRXc3t5WQlKRWHT_sj7xfhocITK3-RoW\" width=\"400\"/>  |\n",
        "\n",
        "```\n",
        "def ackley_function(x):\n",
        "    term1 = -20 * math.exp(-0.2 * math.sqrt(sum(xi ** 2 for xi in x) / len(x)))\n",
        "    term2 = -math.exp(sum(math.cos(2 * math.pi * xi) for xi in x) / len(x))\n",
        "    return 20 + math.e + term1 + term2\n",
        "\n",
        "def convex_function(x):\n",
        "    return (x[0] - 2) ** 2 + 5 * (x[1] - 5) ** 2 + 8 * (x[2] + 8) ** 2 + 3 * (x[3] + 1) ** 2 + 6 * (x[4] - 7) ** 2\n",
        "\n",
        "def griewank_function(x):\n",
        "    sum_term = sum(xi ** 2 for xi in x) / 4000\n",
        "    prod_term = math.cos(x[0])\n",
        "    for i, xi in enumerate(x[1:], start=2):\n",
        "        prod_term *= math.cos(xi / math.sqrt(i))\n",
        "    return 1 + sum_term - prod_term\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RC03wvHwOHjk"
      },
      "source": [
        "# 0. Discrete Problem Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5TkwI0GOHLv"
      },
      "outputs": [],
      "source": [
        "cities = [\n",
        "    (8, 31), (54, 97), (50, 50), (65, 16), (70, 47), (25, 100), (55, 74), (77, 87),\n",
        "    (6, 46), (70, 78), (13, 38), (100, 32), (26, 35), (55, 16), (26, 77), (17, 67),\n",
        "    (40, 36), (38, 27), (33, 2), (48, 9), (62, 20), (17, 92), (30, 2), (80, 75),\n",
        "    (32, 36), (43, 79), (57, 49), (18, 24), (96, 76), (81, 39)\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "hc = hill_climber(\n",
        "            generate_neighbor=generate_neighbor,\n",
        "            objective_function=objective_function,\n",
        "            initial_solution_generator=initial_solution_generator,\n",
        "            mode='min'\n",
        "        )\n",
        "hc.fit()\n",
        "print(f\"First Choice Hill Climber Best Solution: {hc.predict()}\")\n",
        "print(f\"First Choice Hill Climber Best Score: {hc.score()}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
